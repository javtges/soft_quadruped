'''
Quote from:
https://towardsdatascience.com/introduction-to-augmented-random-search-d8d7b55309bd

Let ğ› a positive constant < 1
Let ğ° be the learning rate
Let N the number of perturbations
Let ğœƒ a (p x n) matrix representing the parameters of the policy ğœ‹
Let ğœ¹i a (p x n) matrix representing the ith perturbation
1. While end condition not satisfied do:
2. Generate N perturbations ğœ¹ from a normal distribution
3. Normalize ğœ‹i+ = (ğœƒ+ğ›ğœ¹i)áµ€x and ğœ‹i- = (ğœƒ-ğ›ğœ¹i)áµ€x for i = 1 to N
4. Generate 2N episodes and their 2N rewards using ğœ‹i+ and ğœ‹i- and collect the rewards ri+ and ri-
5. Sort all ğœ¹ by max(ri+, ri-)
6. Update ğœƒ = ğœƒ + (ğ°/(b*ğ¼áµ£)) Î£(ri+ - ri-)ğœ¹i (where i = 1 to b)
7. End While


Policy must have:
Robot state (x,y,velocity)
TG Params (width, height)
Phase of each foot (perhaps?)
Return: TG Params, 8 parameters for leg modifications

    Dimensions: 6 x 10(?)

TG must have:
Input: width, height, timestep (opt)
Find ellipse with width, height, at certain timestep
Return: theta, eps (leg position)



'''
